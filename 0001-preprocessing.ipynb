{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "IMDB=pd.read_csv(\"./database/IMDB Dataset.csv\")\n",
    "IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   review sentiment\n",
      "count                                               50000     50000\n",
      "unique                                              49582         2\n",
      "top     Loved today's show!!! It was a variety and not...  positive\n",
      "freq                                                    5     25000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(IMDB.describe())\n",
    "print(IMDB.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA 진행 결과 IMDB 데이터 셋의 열은 review와 sentiment로 구성,\n",
    "각 열에 해당되는 행의 개수는 총 50000개이며 고유값들은 각각 49582개, 2개임.\n",
    "이 리뷰를 lstm모델을 활용하여 긍정 혹은 부정으로 예측하는 모델을 구축할것임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated Rows:\n",
      "                                                   review sentiment\n",
      "3537   Quite what the producers of this appalling ada...  negative\n",
      "3769   My favourite police series of all time turns t...  positive\n",
      "4391   Beautiful film, pure Cassavetes style. Gena Ro...  positive\n",
      "6352   If you liked the Grinch movie... go watch that...  negative\n",
      "6479   I want very much to believe that the above quo...  negative\n",
      "...                                                  ...       ...\n",
      "49912  This is an incredible piece of drama and power...  positive\n",
      "49950  This was a very brief episode that appeared in...  negative\n",
      "49984  Hello it is I Derrick Cannon and I welcome you...  negative\n",
      "49986  This movie is a disgrace to the Major League F...  negative\n",
      "49991  Les Visiteurs, the first movie about the medie...  negative\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 정제\n",
    "duplicates = IMDB[IMDB.duplicated()]  \n",
    "print(\"Duplicated Rows:\\n\", duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49582</td>\n",
       "      <td>49582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>24884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               49582     49582\n",
       "unique                                              49582         2\n",
       "top     One of the other reviewers has mentioned that ...  positive\n",
       "freq                                                    1     24884"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB = IMDB.drop_duplicates(subset='review') # 중복되는 행 제거\n",
    "IMDB.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        positive\n",
       "1        positive\n",
       "2        positive\n",
       "3        negative\n",
       "4        positive\n",
       "           ...   \n",
       "49995    positive\n",
       "49996    negative\n",
       "49997    negative\n",
       "49998    negative\n",
       "49999    negative\n",
       "Name: sentiment, Length: 49582, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB.loc[:, 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...         1\n",
       "1  A wonderful little production. <br /><br />The...         1\n",
       "2  I thought this was a wonderful way to spend ti...         1\n",
       "3  Basically there's a family where a little boy ...         0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...         1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB.loc[:, 'sentiment'] = IMDB['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "IMDB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/trifull/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3663886/1833480724.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  IMDB['review_cleaned'] = IMDB['review'].apply(clean_text)\n"
     ]
    }
   ],
   "source": [
    "# NOTE: 텍스트 데이터 전처리\n",
    "# 모델의 input을 효율적으로하고 정확한 성능을 내기 위해서 텍스트데이터를 일관된 형식으로 변환하는 과정이 필요함.\n",
    "# 1. 텍스트 정규화 -> \"특수문자\", \"대/소문자\", \"두 칸 이상의 공백\" 제거 \n",
    "# 2. 자연어 처리에서 큰 의미를 가지지 않는다고 알려져 있는 불용어(stopword) 제거 \n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "import re\n",
    "def clean_text(text):\n",
    "    text = text.lower() # 소문자화\n",
    "    text = re.sub(r\"<.*?>\", \"\", text) # HTML태그 제거 \n",
    "    text = re.sub(r\"[^.a-z\\s!?']\", \"\", text) # 특수 문자 및 숫자 제거\n",
    "    text = \" \".join(word for word in text.split() if word not in stop_words) # 불용어 제거\n",
    "    text = re.sub(r'([!?\\'\"])\\1+', r'\\1', text) # !?'이 2개 이상이면 한 개로 만들어줌.\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # 불필요한 공백 제거\n",
    "    return text\n",
    "IMDB['review_cleaned'] = IMDB['review'].apply(clean_text)\n",
    "# pd.Series([len(review) for review in IMDB[\"review_cleaned\"].to_list()]).plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 토큰화\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "IMDB.loc[:,'review_tokenized'] = IMDB.loc[:,'review_cleaned'].apply(tokenizer.tokenize)\n",
    "print(IMDB.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238841"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 단어집합 생성\n",
    "import numpy as np\n",
    "from nltk import FreqDist\n",
    "\n",
    "all_tokens = np.hstack(IMDB[\"review_tokenized\"])\n",
    "\n",
    "# 단어 집합 생성 및 빈도 계산\n",
    "vocab = FreqDist(all_tokens)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32655,\n",
       " {'one': 2,\n",
       "  'reviewers': 3,\n",
       "  'mentioned': 4,\n",
       "  'watching': 5,\n",
       "  'oz': 6,\n",
       "  'episode': 7,\n",
       "  'hooked.': 8,\n",
       "  'right': 9,\n",
       "  'exactly': 10,\n",
       "  'happened': 11,\n",
       "  'me.the': 12,\n",
       "  'first': 13,\n",
       "  'thing': 14,\n",
       "  'struck': 15,\n",
       "  'brutality': 16,\n",
       "  'unflinching': 17,\n",
       "  'scenes': 18,\n",
       "  'violence': 19,\n",
       "  'set': 20,\n",
       "  'word': 21,\n",
       "  'go.': 22,\n",
       "  'trust': 23,\n",
       "  'show': 24,\n",
       "  'faint': 25,\n",
       "  'hearted': 26,\n",
       "  'pulls': 27,\n",
       "  'punches': 28,\n",
       "  'regards': 29,\n",
       "  'drugs': 30,\n",
       "  'sex': 31,\n",
       "  'violence.': 32,\n",
       "  'hardcore': 33,\n",
       "  'classic': 34,\n",
       "  'use': 35,\n",
       "  'called': 36,\n",
       "  'nickname': 37,\n",
       "  'given': 38,\n",
       "  'oswald': 39,\n",
       "  'maximum': 40,\n",
       "  'security': 41,\n",
       "  'state': 42,\n",
       "  'focuses': 43,\n",
       "  'mainly': 44,\n",
       "  'emerald': 45,\n",
       "  'city': 46,\n",
       "  'experimental': 47,\n",
       "  'section': 48,\n",
       "  'prison': 49,\n",
       "  'cells': 50,\n",
       "  'glass': 51,\n",
       "  'fronts': 52,\n",
       "  'face': 53,\n",
       "  'privacy': 54,\n",
       "  'high': 55,\n",
       "  'agenda.': 56,\n",
       "  'em': 57,\n",
       "  'home': 58,\n",
       "  'muslims': 59,\n",
       "  'latinos': 60,\n",
       "  'christians': 61,\n",
       "  'italians': 62,\n",
       "  'irish': 63,\n",
       "  'more': 64,\n",
       "  '...': 65,\n",
       "  '.so': 66,\n",
       "  'death': 67,\n",
       "  'stares': 68,\n",
       "  'dodgy': 69,\n",
       "  'dealings': 70,\n",
       "  'shady': 71,\n",
       "  'never': 72,\n",
       "  'far': 73,\n",
       "  'away.i': 74,\n",
       "  'would': 75,\n",
       "  'say': 76,\n",
       "  'main': 77,\n",
       "  'appeal': 78,\n",
       "  'due': 79,\n",
       "  'fact': 80,\n",
       "  'goes': 81,\n",
       "  'shows': 82,\n",
       "  'forget': 83,\n",
       "  'pretty': 84,\n",
       "  'pictures': 85,\n",
       "  'painted': 86,\n",
       "  'mainstream': 87,\n",
       "  'audiences': 88,\n",
       "  'charm': 89,\n",
       "  'romance': 90,\n",
       "  'mess': 91,\n",
       "  'around.': 92,\n",
       "  'ever': 93,\n",
       "  'saw': 94,\n",
       "  'nasty': 95,\n",
       "  'surreal': 96,\n",
       "  'ready': 97,\n",
       "  'watched': 98,\n",
       "  'developed': 99,\n",
       "  'taste': 100,\n",
       "  'got': 101,\n",
       "  'accustomed': 102,\n",
       "  'levels': 103,\n",
       "  'graphic': 104,\n",
       "  'injustice': 105,\n",
       "  'crooked': 106,\n",
       "  'guards': 107,\n",
       "  'who': 108,\n",
       "  \"'ll\": 109,\n",
       "  'sold': 110,\n",
       "  'inmates': 111,\n",
       "  'kill': 112,\n",
       "  'order': 113,\n",
       "  'get': 114,\n",
       "  'away': 115,\n",
       "  'well': 116,\n",
       "  'mannered': 117,\n",
       "  'middle': 118,\n",
       "  'class': 119,\n",
       "  'turned': 120,\n",
       "  'bitches': 121,\n",
       "  'lack': 122,\n",
       "  'street': 123,\n",
       "  'skills': 124,\n",
       "  'experience': 125,\n",
       "  'may': 126,\n",
       "  'become': 127,\n",
       "  'comfortable': 128,\n",
       "  'uncomfortable': 129,\n",
       "  'viewing': 130,\n",
       "  'touch': 131,\n",
       "  'darker': 132,\n",
       "  'side': 133,\n",
       "  '.': 134,\n",
       "  'wonderful': 135,\n",
       "  'little': 136,\n",
       "  'production.': 137,\n",
       "  'filming': 138,\n",
       "  'technique': 139,\n",
       "  'unassuming': 140,\n",
       "  'fashion': 141,\n",
       "  'gives': 142,\n",
       "  'comforting': 143,\n",
       "  'sometimes': 144,\n",
       "  'discomforting': 145,\n",
       "  'sense': 146,\n",
       "  'realism': 147,\n",
       "  'entire': 148,\n",
       "  'piece.': 149,\n",
       "  'actors': 150,\n",
       "  'extremely': 151,\n",
       "  'chosen': 152,\n",
       "  'michael': 153,\n",
       "  'sheen': 154,\n",
       "  'voices': 155,\n",
       "  'pat': 156,\n",
       "  'too': 157,\n",
       "  '!': 158,\n",
       "  'truly': 159,\n",
       "  'see': 160,\n",
       "  'seamless': 161,\n",
       "  'editing': 162,\n",
       "  'guided': 163,\n",
       "  'references': 164,\n",
       "  'williams': 165,\n",
       "  \"'\": 166,\n",
       "  'diary': 167,\n",
       "  'entries': 168,\n",
       "  'worth': 169,\n",
       "  'written': 170,\n",
       "  'performed': 171,\n",
       "  'masterful': 172,\n",
       "  'production': 173,\n",
       "  'great': 174,\n",
       "  'master': 175,\n",
       "  \"'s\": 176,\n",
       "  'comedy': 177,\n",
       "  'life.': 178,\n",
       "  'really': 179,\n",
       "  'comes': 180,\n",
       "  'things': 181,\n",
       "  'fantasy': 182,\n",
       "  'guard': 183,\n",
       "  'rather': 184,\n",
       "  'traditional': 185,\n",
       "  'techniques': 186,\n",
       "  'remains': 187,\n",
       "  'solid': 188,\n",
       "  'disappears.': 189,\n",
       "  'plays': 190,\n",
       "  'knowledge': 191,\n",
       "  'senses': 192,\n",
       "  'particularly': 193,\n",
       "  'concerning': 194,\n",
       "  'orton': 195,\n",
       "  'halliwell': 196,\n",
       "  'sets': 197,\n",
       "  'flat': 198,\n",
       "  'decorating': 199,\n",
       "  'every': 200,\n",
       "  'surface': 201,\n",
       "  'terribly': 202,\n",
       "  'done': 203,\n",
       "  'thought': 204,\n",
       "  'way': 205,\n",
       "  'spend': 206,\n",
       "  'time': 207,\n",
       "  'hot': 208,\n",
       "  'summer': 209,\n",
       "  'weekend': 210,\n",
       "  'sitting': 211,\n",
       "  'air': 212,\n",
       "  'conditioned': 213,\n",
       "  'theater': 214,\n",
       "  'lighthearted': 215,\n",
       "  'comedy.': 216,\n",
       "  'plot': 217,\n",
       "  'simplistic': 218,\n",
       "  'dialogue': 219,\n",
       "  'witty': 220,\n",
       "  'characters': 221,\n",
       "  'likable': 222,\n",
       "  'even': 223,\n",
       "  'bread': 224,\n",
       "  'suspected': 225,\n",
       "  'serial': 226,\n",
       "  'killer.': 227,\n",
       "  'disappointed': 228,\n",
       "  'realize': 229,\n",
       "  'match': 230,\n",
       "  'point': 231,\n",
       "  'risk': 232,\n",
       "  'addiction': 233,\n",
       "  'proof': 234,\n",
       "  'woody': 235,\n",
       "  'allen': 236,\n",
       "  'still': 237,\n",
       "  'fully': 238,\n",
       "  'control': 239,\n",
       "  'style': 240,\n",
       "  'many': 241,\n",
       "  'us': 242,\n",
       "  'grown': 243,\n",
       "  'i': 244,\n",
       "  \"'d\": 245,\n",
       "  'laughed': 246,\n",
       "  'comedies': 247,\n",
       "  'years': 248,\n",
       "  'dare': 249,\n",
       "  'decade': 250,\n",
       "  '?': 251,\n",
       "  \"'ve\": 252,\n",
       "  'impressed': 253,\n",
       "  'scarlet': 254,\n",
       "  'managed': 255,\n",
       "  'tone': 256,\n",
       "  'sexy': 257,\n",
       "  'image': 258,\n",
       "  'jumped': 259,\n",
       "  'average': 260,\n",
       "  'spirited': 261,\n",
       "  'young': 262,\n",
       "  'crown': 263,\n",
       "  'jewel': 264,\n",
       "  'career': 265,\n",
       "  'devil': 266,\n",
       "  'wears': 267,\n",
       "  'prada': 268,\n",
       "  'interesting': 269,\n",
       "  'superman': 270,\n",
       "  'go': 271,\n",
       "  'friends': 272,\n",
       "  'basically': 273,\n",
       "  'there': 274,\n",
       "  'family': 275,\n",
       "  'boy': 276,\n",
       "  'jake': 277,\n",
       "  'thinks': 278,\n",
       "  'zombie': 279,\n",
       "  'closet': 280,\n",
       "  'parents': 281,\n",
       "  'fighting': 282,\n",
       "  'time.this': 283,\n",
       "  'movie': 284,\n",
       "  'slower': 285,\n",
       "  'soap': 286,\n",
       "  'opera': 287,\n",
       "  'suddenly': 288,\n",
       "  'decides': 289,\n",
       "  'rambo': 290,\n",
       "  'going': 291,\n",
       "  'make': 292,\n",
       "  'film': 293,\n",
       "  'must': 294,\n",
       "  'decide': 295,\n",
       "  'thriller': 296,\n",
       "  'drama': 297,\n",
       "  'watchable.': 298,\n",
       "  'arguing': 299,\n",
       "  'like': 300,\n",
       "  'real': 301,\n",
       "  'totally': 302,\n",
       "  'ruins': 303,\n",
       "  'expected': 304,\n",
       "  'boogeyman': 305,\n",
       "  'similar': 306,\n",
       "  'instead': 307,\n",
       "  'meaningless': 308,\n",
       "  'spots.': 309,\n",
       "  'playing': 310,\n",
       "  'descent': 311,\n",
       "  'dialogs.': 312,\n",
       "  'shots': 313,\n",
       "  'ignore': 314,\n",
       "  'them': 315,\n",
       "  'mattei': 316,\n",
       "  'love': 317,\n",
       "  'money': 318,\n",
       "  'visually': 319,\n",
       "  'stunning': 320,\n",
       "  'watch.': 321,\n",
       "  'mr.': 322,\n",
       "  'offers': 323,\n",
       "  'vivid': 324,\n",
       "  'portrait': 325,\n",
       "  'human': 326,\n",
       "  'relations.': 327,\n",
       "  'seems': 328,\n",
       "  'telling': 329,\n",
       "  'power': 330,\n",
       "  'success': 331,\n",
       "  'people': 332,\n",
       "  'different': 333,\n",
       "  'situations': 334,\n",
       "  'encounter.': 335,\n",
       "  'variation': 336,\n",
       "  'arthur': 337,\n",
       "  'play': 338,\n",
       "  'theme': 339,\n",
       "  'director': 340,\n",
       "  'transfers': 341,\n",
       "  'action': 342,\n",
       "  'present': 343,\n",
       "  'new': 344,\n",
       "  'york': 345,\n",
       "  'meet': 346,\n",
       "  'connect.': 347,\n",
       "  'connected': 348,\n",
       "  'another': 349,\n",
       "  'next': 350,\n",
       "  'person': 351,\n",
       "  'know': 352,\n",
       "  'previous': 353,\n",
       "  'contact.': 354,\n",
       "  'stylishly': 355,\n",
       "  'sophisticated': 356,\n",
       "  'luxurious': 357,\n",
       "  'look.': 358,\n",
       "  'taken': 359,\n",
       "  'live': 360,\n",
       "  'world': 361,\n",
       "  'gets': 362,\n",
       "  'souls': 363,\n",
       "  'picture': 364,\n",
       "  'stages': 365,\n",
       "  'loneliness': 366,\n",
       "  'big': 367,\n",
       "  'best': 368,\n",
       "  'place': 369,\n",
       "  'relations': 370,\n",
       "  'find': 371,\n",
       "  'sincere': 372,\n",
       "  'fulfillment': 373,\n",
       "  'case': 374,\n",
       "  'acting': 375,\n",
       "  'good': 376,\n",
       "  'direction.': 377,\n",
       "  'steve': 378,\n",
       "  'buscemi': 379,\n",
       "  'rosario': 380,\n",
       "  'dawson': 381,\n",
       "  'carol': 382,\n",
       "  'kane': 383,\n",
       "  'imperioli': 384,\n",
       "  'adrian': 385,\n",
       "  'rest': 386,\n",
       "  'talented': 387,\n",
       "  'cast': 388,\n",
       "  'come': 389,\n",
       "  'wish': 390,\n",
       "  'luck': 391,\n",
       "  'await': 392,\n",
       "  'anxiously': 393,\n",
       "  'work': 394,\n",
       "  'probably': 395,\n",
       "  'alltime': 396,\n",
       "  'favorite': 397,\n",
       "  'story': 398,\n",
       "  'sacrifice': 399,\n",
       "  'dedication': 400,\n",
       "  'noble': 401,\n",
       "  'cause': 402,\n",
       "  'preachy': 403,\n",
       "  'boring.': 404,\n",
       "  'old': 405,\n",
       "  'despite': 406,\n",
       "  'seen': 407,\n",
       "  'times': 408,\n",
       "  'last': 409,\n",
       "  'years.': 410,\n",
       "  'paul': 411,\n",
       "  'lukas': 412,\n",
       "  'performance': 413,\n",
       "  'brings': 414,\n",
       "  'tears': 415,\n",
       "  'eyes': 416,\n",
       "  'bette': 417,\n",
       "  'davis': 418,\n",
       "  'sympathetic': 419,\n",
       "  'roles': 420,\n",
       "  'delight.': 421,\n",
       "  'kids': 422,\n",
       "  'grandma': 423,\n",
       "  'says': 424,\n",
       "  'midgets': 425,\n",
       "  'children': 426,\n",
       "  'makes': 427,\n",
       "  'fun': 428,\n",
       "  'mother': 429,\n",
       "  'slow': 430,\n",
       "  'awakening': 431,\n",
       "  'what': 432,\n",
       "  'happening': 433,\n",
       "  'roof': 434,\n",
       "  'believable': 435,\n",
       "  'dozen': 436,\n",
       "  'thumbs': 437,\n",
       "  'they': 438,\n",
       "  'sure': 439,\n",
       "  'resurrection': 440,\n",
       "  'dated': 441,\n",
       "  'series': 442,\n",
       "  'tech': 443,\n",
       "  'today': 444,\n",
       "  'bring': 445,\n",
       "  'back': 446,\n",
       "  'kid': 447,\n",
       "  'excitement': 448,\n",
       "  'me.i': 449,\n",
       "  'grew': 450,\n",
       "  'black': 451,\n",
       "  'white': 452,\n",
       "  'tv': 453,\n",
       "  'gunsmoke': 454,\n",
       "  'hero': 455,\n",
       "  'vote': 456,\n",
       "  'comeback': 457,\n",
       "  'sea': 458,\n",
       "  'need': 459,\n",
       "  'change': 460,\n",
       "  'pace': 461,\n",
       "  'water': 462,\n",
       "  'thank': 463,\n",
       "  'outlet': 464,\n",
       "  'view': 465,\n",
       "  'viewpoints': 466,\n",
       "  'ole': 467,\n",
       "  'believe': 468,\n",
       "  'wan': 469,\n",
       "  'na': 470,\n",
       "  'nice': 471,\n",
       "  'read': 472,\n",
       "  'plus': 473,\n",
       "  'points': 474,\n",
       "  'rhymes': 475,\n",
       "  'lines': 476,\n",
       "  'let': 477,\n",
       "  'leave': 478,\n",
       "  'doubt': 479,\n",
       "  'lets': 480,\n",
       "  'it': 481,\n",
       "  'amazing': 482,\n",
       "  'fresh': 483,\n",
       "  'innovative': 484,\n",
       "  'idea': 485,\n",
       "  'aired.': 486,\n",
       "  'brilliant': 487,\n",
       "  'dropped': 488,\n",
       "  'that.': 489,\n",
       "  'funny': 490,\n",
       "  'anymore': 491,\n",
       "  'continued': 492,\n",
       "  'decline': 493,\n",
       "  'complete': 494,\n",
       "  'waste': 495,\n",
       "  'disgraceful': 496,\n",
       "  'writing': 497,\n",
       "  'painfully': 498,\n",
       "  'bad': 499,\n",
       "  'performances': 500,\n",
       "  'almost': 501,\n",
       "  'mildly': 502,\n",
       "  'entertaining': 503,\n",
       "  'respite': 504,\n",
       "  'air.': 505,\n",
       "  'hard': 506,\n",
       "  'creator': 507,\n",
       "  'original': 508,\n",
       "  'also': 509,\n",
       "  'chose': 510,\n",
       "  'band': 511,\n",
       "  'hacks': 512,\n",
       "  'followed.': 513,\n",
       "  'recognize': 514,\n",
       "  'brilliance': 515,\n",
       "  'fit': 516,\n",
       "  'replace': 517,\n",
       "  'mediocrity': 518,\n",
       "  'felt': 519,\n",
       "  'give': 520,\n",
       "  'stars': 521,\n",
       "  'respect': 522,\n",
       "  'made': 523,\n",
       "  'huge': 524,\n",
       "  'success.': 525,\n",
       "  'awful.': 526,\n",
       "  'ca': 527,\n",
       "  \"n't\": 528,\n",
       "  'encouraged': 529,\n",
       "  'positive': 530,\n",
       "  'comments': 531,\n",
       "  'looking': 532,\n",
       "  'forward': 533,\n",
       "  'film.': 534,\n",
       "  'mistake.': 535,\n",
       "  'films': 536,\n",
       "  'worst': 537,\n",
       "  'awful': 538,\n",
       "  'pacing': 539,\n",
       "  'storyline': 540,\n",
       "  \"'acting\": 541,\n",
       "  'soundtrack': 542,\n",
       "  'song': 543,\n",
       "  'lame': 544,\n",
       "  'country': 545,\n",
       "  'tune': 546,\n",
       "  'played': 547,\n",
       "  'less': 548,\n",
       "  'four': 549,\n",
       "  'times.': 550,\n",
       "  'looks': 551,\n",
       "  'cheap': 552,\n",
       "  'boring': 553,\n",
       "  'extreme.': 554,\n",
       "  'rarely': 555,\n",
       "  'happy': 556,\n",
       "  'end': 557,\n",
       "  'credits': 558,\n",
       "  'prevents': 559,\n",
       "  'giving': 560,\n",
       "  'score': 561,\n",
       "  'harvey': 562,\n",
       "  'keitel': 563,\n",
       "  'least': 564,\n",
       "  'making': 565,\n",
       "  'bit': 566,\n",
       "  'effort.': 567,\n",
       "  'only': 568,\n",
       "  'gut': 569,\n",
       "  'wrenching': 570,\n",
       "  'laughter': 571,\n",
       "  'movie.': 572,\n",
       "  'hell': 573,\n",
       "  'mom': 574,\n",
       "  'liked': 575,\n",
       "  'camp': 576,\n",
       "  'phil': 577,\n",
       "  'alien': 578,\n",
       "  'quirky': 579,\n",
       "  'humour': 580,\n",
       "  'based': 581,\n",
       "  'around': 582,\n",
       "  'oddness': 583,\n",
       "  'everything': 584,\n",
       "  'actual': 585,\n",
       "  'odd': 586,\n",
       "  'progressed': 587,\n",
       "  'jokes': 588,\n",
       "  'low': 589,\n",
       "  'budget': 590,\n",
       "  'thats': 591,\n",
       "  'problem': 592,\n",
       "  'eventually': 593,\n",
       "  'lost': 594,\n",
       "  'imagine': 595,\n",
       "  'stoner': 596,\n",
       "  'currently': 597,\n",
       "  'something': 598,\n",
       "  'better': 599,\n",
       "  'try': 600,\n",
       "  'brother': 601,\n",
       "  'planet': 602,\n",
       "  'came': 603,\n",
       "  'out.': 604,\n",
       "  'recall': 605,\n",
       "  'scariest': 606,\n",
       "  'scene': 607,\n",
       "  'bird': 608,\n",
       "  'eating': 609,\n",
       "  'men': 610,\n",
       "  'dangling': 611,\n",
       "  'helplessly': 612,\n",
       "  'horror.': 613,\n",
       "  'cheesy': 614,\n",
       "  'b': 615,\n",
       "  'saturday': 616,\n",
       "  'afternoons': 617,\n",
       "  'tired': 618,\n",
       "  'formula': 619,\n",
       "  'monster': 620,\n",
       "  'type': 621,\n",
       "  'movies': 622,\n",
       "  'usually': 623,\n",
       "  'included': 624,\n",
       "  'beautiful': 625,\n",
       "  'woman': 626,\n",
       "  'might': 627,\n",
       "  'daughter': 628,\n",
       "  'professor': 629,\n",
       "  'resolution': 630,\n",
       "  'died': 631,\n",
       "  'end.': 632,\n",
       "  'care': 633,\n",
       "  'much': 634,\n",
       "  'romantic': 635,\n",
       "  'angle': 636,\n",
       "  'year': 637,\n",
       "  'predictable': 638,\n",
       "  'plots.': 639,\n",
       "  'unintentional': 640,\n",
       "  'later': 641,\n",
       "  'psycho': 642,\n",
       "  'loved': 643,\n",
       "  'star': 644,\n",
       "  'janet': 645,\n",
       "  'leigh': 646,\n",
       "  'bumped': 647,\n",
       "  'early': 648,\n",
       "  'sat': 649,\n",
       "  'took': 650,\n",
       "  'notice': 651,\n",
       "  'point.': 652,\n",
       "  'since': 653,\n",
       "  'screenwriters': 654,\n",
       "  'scary': 655,\n",
       "  'possible': 656,\n",
       "  'wellworn': 657,\n",
       "  'formula.': 658,\n",
       "  'rules': 659,\n",
       "  'im': 660,\n",
       "  'fan': 661,\n",
       "  'boll': 662,\n",
       "  'are.': 663,\n",
       "  'enjoyed': 664,\n",
       "  'postal': 665,\n",
       "  'maybe': 666,\n",
       "  'one.': 667,\n",
       "  'apparently': 668,\n",
       "  'bought': 669,\n",
       "  'rights': 670,\n",
       "  'cry': 671,\n",
       "  'long': 672,\n",
       "  'ago': 673,\n",
       "  'game': 674,\n",
       "  'killing': 675,\n",
       "  'infiltrating': 676,\n",
       "  'secret': 677,\n",
       "  'research': 678,\n",
       "  'labs': 679,\n",
       "  'located': 680,\n",
       "  'tropical': 681,\n",
       "  'island': 682,\n",
       "  'warned': 683,\n",
       "  'mr': 684,\n",
       "  'together': 685,\n",
       "  'along': 686,\n",
       "  'legion': 687,\n",
       "  'feeling': 688,\n",
       "  'invites': 689,\n",
       "  'three': 690,\n",
       "  'countrymen': 691,\n",
       "  'with.': 692,\n",
       "  'players': 693,\n",
       "  'names': 694,\n",
       "  'til': 695,\n",
       "  'schweiger': 696,\n",
       "  'udo': 697,\n",
       "  'kier': 698,\n",
       "  'actually': 699,\n",
       "  'tale': 700,\n",
       "  'jack': 701,\n",
       "  'carver': 702,\n",
       "  'yes': 703,\n",
       "  'german': 704,\n",
       "  'hail': 705,\n",
       "  'dudes': 706,\n",
       "  'however': 707,\n",
       "  'complained': 708,\n",
       "  'he': 709,\n",
       "  'staying': 710,\n",
       "  'true': 711,\n",
       "  'whole': 712,\n",
       "  'agenda': 713,\n",
       "  'perspective': 714,\n",
       "  'looked': 715,\n",
       "  'kicking': 716,\n",
       "  'beyond': 717,\n",
       "  'demented.': 718,\n",
       "  'evil': 719,\n",
       "  'mad': 720,\n",
       "  'scientist': 721,\n",
       "  'dr.': 722,\n",
       "  'called.': 723,\n",
       "  'performing': 724,\n",
       "  'topsecret': 725,\n",
       "  'reminds': 726,\n",
       "  'spoiler': 727,\n",
       "  'vancouver': 728,\n",
       "  'reason.': 729,\n",
       "  'palm': 730,\n",
       "  'trees': 731,\n",
       "  'here.': 732,\n",
       "  'rich': 733,\n",
       "  'gone': 734,\n",
       "  'started': 735,\n",
       "  'can': 736,\n",
       "  'not': 737,\n",
       "  'stay': 738,\n",
       "  'shenanigans': 739,\n",
       "  'delivers': 740,\n",
       "  'meaning': 741,\n",
       "  'mentioning': 742,\n",
       "  'imply': 743,\n",
       "  'areas': 744,\n",
       "  'boat': 745,\n",
       "  'scenes.': 746,\n",
       "  'squad': 747,\n",
       "  'enters': 748,\n",
       "  'reeks': 749,\n",
       "  'that': 750,\n",
       "  'poop': 751,\n",
       "  'take': 752,\n",
       "  'btw': 753,\n",
       "  'annoying': 754,\n",
       "  'sidekick': 755,\n",
       "  'shoot': 756,\n",
       "  'minutes': 757,\n",
       "  'screen': 758,\n",
       "  'appreciate': 759,\n",
       "  'trying': 760,\n",
       "  'shakespeare': 761,\n",
       "  'masses': 762,\n",
       "  'ruin': 763,\n",
       "  \"'the\": 764,\n",
       "  'scottish': 765,\n",
       "  'know.': 766,\n",
       "  'certain': 767,\n",
       "  'hence': 768,\n",
       "  'tried': 769,\n",
       "  'victorian': 770,\n",
       "  'words': 771,\n",
       "  'improve': 772,\n",
       "  'write': 773,\n",
       "  'ten': 774,\n",
       "  'text': 775,\n",
       "  'english': 776,\n",
       "  'composition': 777,\n",
       "  'forte': 778,\n",
       "  'keep': 779,\n",
       "  'saying': 780,\n",
       "  'cut': 781,\n",
       "  'fantastic': 782,\n",
       "  'prisoners': 783,\n",
       "  'famous.': 784,\n",
       "  'george': 785,\n",
       "  'clooney': 786,\n",
       "  \"'m\": 787,\n",
       "  'roll': 788,\n",
       "  'bad.': 789,\n",
       "  'man': 790,\n",
       "  'constant': 791,\n",
       "  'everybody.': 792,\n",
       "  'greetings': 793,\n",
       "  'bart': 794,\n",
       "  'kind': 795,\n",
       "  'drawn': 796,\n",
       "  'erotic': 797,\n",
       "  'amateurish': 798,\n",
       "  'unbelievable': 799,\n",
       "  'bits': 800,\n",
       "  'seen.': 801,\n",
       "  'sort': 802,\n",
       "  'school': 803,\n",
       "  'project.': 804,\n",
       "  'rosanna': 805,\n",
       "  'arquette': 806,\n",
       "  'thinking': 807,\n",
       "  'stock': 808,\n",
       "  'bizarre': 809,\n",
       "  'supposed': 810,\n",
       "  'midwest': 811,\n",
       "  'town': 812,\n",
       "  'involved': 813,\n",
       "  'lessons': 814,\n",
       "  'learned': 815,\n",
       "  'insights': 816,\n",
       "  'stilted': 817,\n",
       "  'quite': 818,\n",
       "  'ridiculous': 819,\n",
       "  'lots': 820,\n",
       "  'skin': 821,\n",
       "  'intrigues': 822,\n",
       "  'videotaped': 823,\n",
       "  'nonsense': 824,\n",
       "  '.what': 825,\n",
       "  'bisexual': 826,\n",
       "  'relationship': 827,\n",
       "  'nowhere': 828,\n",
       "  'heterosexual': 829,\n",
       "  'encounters.': 830,\n",
       "  'absurd': 831,\n",
       "  'dance': 832,\n",
       "  'everybody': 833,\n",
       "  'stereotyped': 834,\n",
       "  'pass': 835,\n",
       "  'million': 836,\n",
       "  'miles': 837,\n",
       "  'wasted': 838,\n",
       "  'could': 839,\n",
       "  'spent': 840,\n",
       "  'starving': 841,\n",
       "  'aids': 842,\n",
       "  'africa': 843,\n",
       "  '..': 844,\n",
       "  'simply': 845,\n",
       "  'them.': 846,\n",
       "  'fails': 847,\n",
       "  'capture': 848,\n",
       "  'flavor': 849,\n",
       "  'terror': 850,\n",
       "  'title.': 851,\n",
       "  'liam': 852,\n",
       "  'neeson': 853,\n",
       "  'excellent': 854,\n",
       "  'always': 855,\n",
       "  'holds': 856,\n",
       "  'exception': 857,\n",
       "  'owen': 858,\n",
       "  'wilson': 859,\n",
       "  'feel': 860,\n",
       "  'character': 861,\n",
       "  'luke.': 862,\n",
       "  'major': 863,\n",
       "  'fault': 864,\n",
       "  'version': 865,\n",
       "  'strayed': 866,\n",
       "  'shirley': 867,\n",
       "  'jackson': 868,\n",
       "  'attempts': 869,\n",
       "  'grandiose': 870,\n",
       "  'thrill': 871,\n",
       "  'earlier': 872,\n",
       "  'trade': 873,\n",
       "  'special': 874,\n",
       "  'effects.': 875,\n",
       "  'enjoy': 876,\n",
       "  'friction': 877,\n",
       "  'older': 878,\n",
       "  'top': 879,\n",
       "  'movies.': 880,\n",
       "  'horrible.': 881,\n",
       "  'continuous': 882,\n",
       "  'minute': 883,\n",
       "  'fight': 884,\n",
       "  'another.': 885,\n",
       "  'chance': 886,\n",
       "  'development': 887,\n",
       "  'busy': 888,\n",
       "  'running': 889,\n",
       "  'sword': 890,\n",
       "  'emotional': 891,\n",
       "  'attachment': 892,\n",
       "  'except': 893,\n",
       "  'machine': 894,\n",
       "  'wanted': 895,\n",
       "  'destroy': 896,\n",
       "  'blatantly': 897,\n",
       "  'stolen': 898,\n",
       "  'lotr': 899,\n",
       "  'wars': 900,\n",
       "  'matrix.': 901,\n",
       "  'ghost': 902,\n",
       "  'final': 903,\n",
       "  'yoda': 904,\n",
       "  'spider': 905,\n",
       "  'beginning': 906,\n",
       "  'frodo': 907,\n",
       "  'attacked': 908,\n",
       "  'return': 909,\n",
       "  'elijah': 910,\n",
       "  'wood': 911,\n",
       "  'victim': 912,\n",
       "  'wait': 913,\n",
       "  'hypnotizes': 914,\n",
       "  'stings': 915,\n",
       "  'wraps': 916,\n",
       "  'up': 917,\n",
       "  'hello': 918,\n",
       "  'and': 919,\n",
       "  'vs.': 920,\n",
       "  'humans': 921,\n",
       "  'terminator': 922,\n",
       "  'examples': 923,\n",
       "  'someone': 924,\n",
       "  'tell': 925,\n",
       "  'nazi': 926,\n",
       "  'juvenile': 927,\n",
       "  'line': 928,\n",
       "  'rushed': 929,\n",
       "  'conclusion.': 930,\n",
       "  'adult': 931,\n",
       "  'either.': 932,\n",
       "  'disappointment': 933,\n",
       "  'least.': 934,\n",
       "  'save': 935,\n",
       "  'remember': 936,\n",
       "  'filmit': 937,\n",
       "  'cinema': 938,\n",
       "  'dark': 939,\n",
       "  'places': 940,\n",
       "  'nervous': 941,\n",
       "  'dad': 942,\n",
       "  'sister': 943,\n",
       "  'england.': 944,\n",
       "  'tigers': 945,\n",
       "  'snow': 946,\n",
       "  'appearance': 947,\n",
       "  'grizzly': 948,\n",
       "  'adams': 949,\n",
       "  'actor': 950,\n",
       "  'dan': 951,\n",
       "  'think': 952,\n",
       "  'shot': 953,\n",
       "  'dies.': 954,\n",
       "  'anyone': 955,\n",
       "  'knows': 956,\n",
       "  'dvd': 957,\n",
       "  'etc': 958,\n",
       "  'please': 959,\n",
       "  'know.the': 960,\n",
       "  'fitness': 961,\n",
       "  'club': 962,\n",
       "  'shame': 963,\n",
       "  'nearest': 964,\n",
       "  'hear': 965,\n",
       "  'others': 966,\n",
       "  'stinkers': 967,\n",
       "  'nominated': 968,\n",
       "  'golden': 969,\n",
       "  'globe.': 970,\n",
       "  'famous': 971,\n",
       "  'female': 972,\n",
       "  'renaissance': 973,\n",
       "  'painter': 974,\n",
       "  'mangled': 975,\n",
       "  'recognition.': 976,\n",
       "  'complaint': 977,\n",
       "  'liberties': 978,\n",
       "  'facts': 979,\n",
       "  'perfectly': 980,\n",
       "  'fine.': 981,\n",
       "  'accounts': 982,\n",
       "  'artist': 983,\n",
       "  'script': 984,\n",
       "  'suppose': 985,\n",
       "  'enough': 986,\n",
       "  'naked': 987,\n",
       "  'factual': 988,\n",
       "  'version.': 989,\n",
       "  'hurriedly': 990,\n",
       "  'capped': 991,\n",
       "  'summary': 992,\n",
       "  'life': 993,\n",
       "  'saved': 994,\n",
       "  'couple': 995,\n",
       "  'hours': 996,\n",
       "  'favored': 997,\n",
       "  'brevity': 998,\n",
       "  'die': 999,\n",
       "  'sequels': 1000,\n",
       "  'surprise': 1001,\n",
       "  ...})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FREQ_THRESHOLD = 3\n",
    "vocab = {key: value for key, value in vocab.items() if value >= FREQ_THRESHOLD}\n",
    "\n",
    "# 단어와 인덱스 할당\n",
    "# 단어 인덱스를 2부터 시작하여 word2idx 생성 -> 레이블 데이터를 1과 0으로 설정 했기 때문\n",
    "word2idx = {word: idx + 2 for idx, (word, _) in enumerate(vocab.items())}\n",
    "word2idx[\"<pad>\"] = 0  # 패딩을 위한 인덱스 0 예약\n",
    "word2idx[\"<unk>\"] = 1  # 알 수 없는 단어를 위한 인덱스 1 예약\n",
    "VOCAB_SIZE = len(word2idx)\n",
    "\n",
    "VOCAB_SIZE, word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [one, reviewers, mentioned, watching, oz, epis...\n",
       "1        [wonderful, little, production., filming, tech...\n",
       "2        [thought, wonderful, way, spend, time, hot, su...\n",
       "3        [basically, there, 's, family, little, boy, ja...\n",
       "4        [petter, mattei, 's, love, time, money, visual...\n",
       "                               ...                        \n",
       "49995    [thought, movie, right, good, job., creative, ...\n",
       "49996    [bad, plot, bad, dialogue, bad, acting, idioti...\n",
       "49997    [catholic, taught, parochial, elementary, scho...\n",
       "49998    [i, 'm, going, disagree, previous, comment, si...\n",
       "49999    [one, expects, star, trek, movies, high, art, ...\n",
       "Name: review_tokenized, Length: 49582, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB['review_tokenized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3640961/191866984.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  IMDB[\"review_numbered\"] = IMDB[\"review_tokenized\"].apply(lambda _X: [word_to_num(word) for word in _X])\n",
      "/tmp/ipykernel_3640961/191866984.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  IMDB[\"token_length\"] = IMDB[\"review_numbered\"].apply(lambda _X: len(_X))\n"
     ]
    }
   ],
   "source": [
    "# 4. 맵핑(단어 집합을 데이터에 적용)\n",
    "def word_to_num(word):\n",
    "    try:\n",
    "        return word2idx[word]  # 글자를 해당되는 정수로 변환\n",
    "    except KeyError:  # 단어 집합에 없는 단어일 경우 unk로 대체된다.\n",
    "        return word2idx[\"<unk>\"]  # unk의 인덱스로 변환\n",
    "\n",
    "\n",
    "IMDB[\"review_numbered\"] = IMDB[\"review_tokenized\"].apply(lambda _X: [word_to_num(word) for word in _X])\n",
    "IMDB[\"token_length\"] = IMDB[\"review_numbered\"].apply(lambda _X: len(_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMDB[\"token_length\"].plot.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGdCAYAAADzOWwgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqB0lEQVR4nO3df3BV9Z3/8dct+WFIkysBkstdImZrYIFEpoY2hKqgQIASI9JdsLERleVHkR9ZwqCsf4i7ToIwBttNVaQMiKKx7cCus2IkFoylIfwIRIEiZRX5IbkEabhJICaYnO8fDufbS/gRLje5CZ/nY+bMcM9533M/5zPHycvP+ZxzHJZlWQIAADDY94LdAAAAgGAjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI9ABAAAjBcS7AZ0FS0tLTp58qSioqLkcDiC3RwAANAGlmWprq5Obrdb3/velceBCERtdPLkScXHxwe7GQAAwA/Hjx9X3759r7idQNRGUVFRkr7r0Ojo6CC3BgAAtEVtba3i4+Ptv+NXQiBqo4uXyaKjowlEAAB0Mdea7sKkagAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA4wU1EC1ZskQOh8Nncblc9nbLsrRkyRK53W5FRERo5MiROnDggM8+GhsbNXfuXPXq1UuRkZHKzMzUiRMnfGpqamqUnZ0tp9Mpp9Op7OxsnT17tiMOEQAAdAFBHyEaPHiwqqqq7GXfvn32tmXLlqmgoECFhYXatWuXXC6XxowZo7q6OrsmJydHGzduVFFRkbZt26b6+nplZGSoubnZrsnKylJlZaWKi4tVXFysyspKZWdnd+hxAgCAzivoD2YMCQnxGRW6yLIsvfTSS3rmmWc0adIkSdLrr7+uuLg4vfXWW5o5c6a8Xq9Wr16tN954Q6NHj5Ykvfnmm4qPj9eHH36osWPH6uDBgyouLlZ5eblSU1MlSatWrVJaWpoOHTqkAQMGdNzBAgCATinoI0SHDx+W2+1WQkKCHn74YX3xxReSpCNHjsjj8Sg9Pd2uDQ8P14gRI1RWViZJqqio0IULF3xq3G63kpKS7Jrt27fL6XTaYUiShg0bJqfTaddcTmNjo2pra30WAABwcwpqIEpNTdW6dev0wQcfaNWqVfJ4PBo+fLjOnDkjj8cjSYqLi/P5TlxcnL3N4/EoLCxMPXr0uGpNbGxsq9+OjY21ay4nPz/fnnPkdDp5sSsAADexoAai8ePH62c/+5mSk5M1evRovffee5K+uzR20aXvHrEs65rvI7m05nL119rP4sWL5fV67eX48eNtOiYAAND1BP2S2d+LjIxUcnKyDh8+bM8runQUp7q62h41crlcampqUk1NzVVrTp061eq3Tp8+3Wr06e+Fh4fbL3Llha4AANzcOlUgamxs1MGDB9WnTx8lJCTI5XKppKTE3t7U1KTS0lINHz5ckpSSkqLQ0FCfmqqqKu3fv9+uSUtLk9fr1c6dO+2aHTt2yOv12jUAAMBsQb3LbOHChXrggQd02223qbq6Ws8//7xqa2s1depUORwO5eTkKC8vT4mJiUpMTFReXp66d++urKwsSZLT6dS0adOUm5urnj17KiYmRgsXLrQvwUnSwIEDNW7cOE2fPl0rV66UJM2YMUMZGRncYYYOc/vT7/n93S+XTghgSwAAlxPUQHTixAn9/Oc/19dff63evXtr2LBhKi8vV79+/SRJixYtUkNDg2bPnq2amhqlpqZq8+bNioqKsvexYsUKhYSEaPLkyWpoaNCoUaO0du1adevWza5Zv3695s2bZ9+NlpmZqcLCwo49WAAA0Gk5LMuygt2IrqC2tlZOp1Ner5f5RLhujBABQHC09e93p5pDBAAAEAwEIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwXlBf7gp0JTfyPjIAQOfGCBEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGC8ThOI8vPz5XA4lJOTY6+zLEtLliyR2+1WRESERo4cqQMHDvh8r7GxUXPnzlWvXr0UGRmpzMxMnThxwqempqZG2dnZcjqdcjqdys7O1tmzZzvgqAAAQFfQKQLRrl279Nprr+nOO+/0Wb9s2TIVFBSosLBQu3btksvl0pgxY1RXV2fX5OTkaOPGjSoqKtK2bdtUX1+vjIwMNTc32zVZWVmqrKxUcXGxiouLVVlZqezs7A47PgAA0LkFPRDV19frkUce0apVq9SjRw97vWVZeumll/TMM89o0qRJSkpK0uuvv67z58/rrbfekiR5vV6tXr1aL774okaPHq0f/vCHevPNN7Vv3z59+OGHkqSDBw+quLhYv/3tb5WWlqa0tDStWrVK//u//6tDhw4F5ZgBAEDnEvRA9OSTT2rChAkaPXq0z/ojR47I4/EoPT3dXhceHq4RI0aorKxMklRRUaELFy741LjdbiUlJdk127dvl9PpVGpqql0zbNgwOZ1Ou+ZyGhsbVVtb67MAAICbU0gwf7yoqEh79uzRrl27Wm3zeDySpLi4OJ/1cXFxOnr0qF0TFhbmM7J0sebi9z0ej2JjY1vtPzY21q65nPz8fD333HPXd0AAAKBLCtoI0fHjxzV//ny9+eabuuWWW65Y53A4fD5bltVq3aUurblc/bX2s3jxYnm9Xns5fvz4VX8TAAB0XUELRBUVFaqurlZKSopCQkIUEhKi0tJS/frXv1ZISIg9MnTpKE51dbW9zeVyqampSTU1NVetOXXqVKvfP336dKvRp78XHh6u6OhonwUAANycghaIRo0apX379qmystJehg4dqkceeUSVlZX6x3/8R7lcLpWUlNjfaWpqUmlpqYYPHy5JSklJUWhoqE9NVVWV9u/fb9ekpaXJ6/Vq586dds2OHTvk9XrtGgAAYLagzSGKiopSUlKSz7rIyEj17NnTXp+Tk6O8vDwlJiYqMTFReXl56t69u7KysiRJTqdT06ZNU25urnr27KmYmBgtXLhQycnJ9iTtgQMHaty4cZo+fbpWrlwpSZoxY4YyMjI0YMCADjxiAADQWQV1UvW1LFq0SA0NDZo9e7ZqamqUmpqqzZs3Kyoqyq5ZsWKFQkJCNHnyZDU0NGjUqFFau3atunXrZtesX79e8+bNs+9Gy8zMVGFhYYcfDwAA6JwclmVZwW5EV1BbWyun0ymv18t8IkPd/vR7QfndL5dOCMrvAsDNoK1/v4P+HCIAAIBgIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYLCXYDAFzd7U+/5/d3v1w6IYAtAYCbFyNEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxeDAjcBPjoY4A0DaMEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI9ABAAAjMdziGCUG3kuDwDg5sUIEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwXlAD0SuvvKI777xT0dHRio6OVlpamt5//317u2VZWrJkidxutyIiIjRy5EgdOHDAZx+NjY2aO3euevXqpcjISGVmZurEiRM+NTU1NcrOzpbT6ZTT6VR2drbOnj3bEYcIAAC6AL8C0ZEjRwLy43379tXSpUu1e/du7d69W/fff78efPBBO/QsW7ZMBQUFKiws1K5du+RyuTRmzBjV1dXZ+8jJydHGjRtVVFSkbdu2qb6+XhkZGWpubrZrsrKyVFlZqeLiYhUXF6uyslLZ2dkBOQYAAND1OSzLsq73S926ddO9996radOm6Z//+Z91yy23BKxBMTExWr58uZ544gm53W7l5OToqaeekvTdaFBcXJxeeOEFzZw5U16vV71799Ybb7yhKVOmSJJOnjyp+Ph4bdq0SWPHjtXBgwc1aNAglZeXKzU1VZJUXl6utLQ0ffbZZxowYECb2lVbWyun0ymv16vo6OiAHS86Fu8ya7svl04IdhMA4Ia19e+3XyNEn3zyiX74wx8qNzdXLpdLM2fO1M6dO/1urCQ1NzerqKhI586dU1pamo4cOSKPx6P09HS7Jjw8XCNGjFBZWZkkqaKiQhcuXPCpcbvdSkpKsmu2b98up9NphyFJGjZsmJxOp10DAADM5lcgSkpKUkFBgb766iutWbNGHo9Hd999twYPHqyCggKdPn26zfvat2+fvv/97ys8PFyzZs3Sxo0bNWjQIHk8HklSXFycT31cXJy9zePxKCwsTD169LhqTWxsbKvfjY2NtWsup7GxUbW1tT4LAAC4Od3QpOqQkBA99NBD+t3vfqcXXnhBn3/+uRYuXKi+ffvq0UcfVVVV1TX3MWDAAFVWVqq8vFy//OUvNXXqVP3lL3+xtzscDp96y7JarbvUpTWXq7/WfvLz8+1J2E6nU/Hx8dc8FgAA0DXdUCDavXu3Zs+erT59+qigoEALFy7U559/ri1btuirr77Sgw8+eM19hIWF6Y477tDQoUOVn5+vIUOG6Fe/+pVcLpcktRrFqa6utkeNXC6XmpqaVFNTc9WaU6dOtfrd06dPtxp9+nuLFy+W1+u1l+PHj1/zWAAAQNfkVyAqKChQcnKyhg8frpMnT2rdunU6evSonn/+eSUkJOgnP/mJVq5cqT179lz3vi3LUmNjoxISEuRyuVRSUmJva2pqUmlpqYYPHy5JSklJUWhoqE9NVVWV9u/fb9ekpaXJ6/X6zHHasWOHvF6vXXM54eHh9uMALi4AAODmFOLPl1555RU98cQTevzxx+2RnEvddtttWr169VX38+///u8aP3684uPjVVdXp6KiIn300UcqLi6Ww+FQTk6O8vLylJiYqMTEROXl5al79+7KysqSJDmdTk2bNk25ubnq2bOnYmJitHDhQiUnJ2v06NGSpIEDB2rcuHGaPn26Vq5cKUmaMWOGMjIy2nyHGQAAuLn5FYgOHz58zZqwsDBNnTr1qjWnTp1Sdna2qqqq5HQ6deedd6q4uFhjxoyRJC1atEgNDQ2aPXu2ampqlJqaqs2bNysqKsrex4oVKxQSEqLJkyeroaFBo0aN0tq1a9WtWze7Zv369Zo3b559N1pmZqYKCwv9OXQAAHAT8us5RGvWrNH3v/99/cu//IvP+t///vc6f/78NYNQV8RziG4OPIeo7XgOEYCbQbs+h2jp0qXq1atXq/WxsbHKy8vzZ5cAAABB41cgOnr0qBISElqt79evn44dO3bDjQIAAOhIfgWi2NhYffrpp63Wf/LJJ+rZs+cNNwoAAKAj+RWIHn74Yc2bN09bt25Vc3OzmpubtWXLFs2fP18PP/xwoNsIAADQrvy6y+z555/X0aNHNWrUKIWEfLeLlpYWPfroo8whAgAAXY5fgSgsLEzvvPOO/vM//1OffPKJIiIilJycrH79+gW6fQAAAO3Or0B0Uf/+/dW/f/9AtQUAACAo/ApEzc3NWrt2rf74xz+qurpaLS0tPtu3bNkSkMYBAAB0BL8C0fz587V27VpNmDBBSUlJ13z7PAAAQGfmVyAqKirS7373O/30pz8NdHsAAAA6nF+33YeFhemOO+4IdFsAAACCwq9AlJubq1/96lfy4zVoAAAAnY5fl8y2bdumrVu36v3339fgwYMVGhrqs33Dhg0BaRwAAEBH8CsQ3XrrrXrooYcC3RYAAICg8CsQrVmzJtDtAAAACBq/5hBJ0rfffqsPP/xQK1euVF1dnSTp5MmTqq+vD1jjAAAAOoJfI0RHjx7VuHHjdOzYMTU2NmrMmDGKiorSsmXL9M033+jVV18NdDsBAADajV8jRPPnz9fQoUNVU1OjiIgIe/1DDz2kP/7xjwFrHAAAQEfw+y6zP//5zwoLC/NZ369fP3311VcBaRgAAEBH8WuEqKWlRc3Nza3WnzhxQlFRUTfcKAAAgI7kVyAaM2aMXnrpJfuzw+FQfX29nn32WV7nAQAAuhy/LpmtWLFC9913nwYNGqRvvvlGWVlZOnz4sHr16qW333470G0EAABoV34FIrfbrcrKSr399tvas2ePWlpaNG3aND3yyCM+k6wBAAC6Ar8CkSRFREToiSee0BNPPBHI9gAAAHQ4vwLRunXrrrr90Ucf9asxAAAAweBXIJo/f77P5wsXLuj8+fMKCwtT9+7dCUQAAKBL8esus5qaGp+lvr5ehw4d0t13382kagAA0OX4/S6zSyUmJmrp0qWtRo8AAAA6u4AFIknq1q2bTp48GchdAgAAtDu/5hC9++67Pp8ty1JVVZUKCwv1k5/8JCANAwAA6Ch+BaKJEyf6fHY4HOrdu7fuv/9+vfjii4FoFwAAQIfxKxC1tLQEuh0AAABBE9A5RAAAAF2RXyNECxYsaHNtQUGBPz8BAADQYfwKRHv37tWePXv07bffasCAAZKkv/71r+rWrZvuuusuu87hcASmlQAAAO3Ir0D0wAMPKCoqSq+//rp69Ogh6buHNT7++OO65557lJubG9BGAgAAtCe/5hC9+OKLys/Pt8OQJPXo0UPPP/88d5kBAIAux68RotraWp06dUqDBw/2WV9dXa26urqANAxAcN3+9Ht+f/fLpRMC2BIAaH9+jRA99NBDevzxx/WHP/xBJ06c0IkTJ/SHP/xB06ZN06RJkwLdRgAAgHbl1wjRq6++qoULF+oXv/iFLly48N2OQkI0bdo0LV++PKANBAAAaG9+BaLu3bvr5Zdf1vLly/X555/LsizdcccdioyMDHT7AAAA2t0NPZixqqpKVVVV6t+/vyIjI2VZVqDaBQAA0GH8CkRnzpzRqFGj1L9/f/30pz9VVVWVJOlf//VfueUeAAB0OX4Fon/7t39TaGiojh07pu7du9vrp0yZouLi4oA1DgAAoCP4NYdo8+bN+uCDD9S3b1+f9YmJiTp69GhAGgYAANBR/BohOnfunM/I0EVff/21wsPDb7hRAAAAHcmvQHTvvfdq3bp19meHw6GWlhYtX75c9913X8AaBwAA0BH8umS2fPlyjRw5Urt371ZTU5MWLVqkAwcO6G9/+5v+/Oc/B7qNAAAA7cqvEaJBgwbp008/1Y9//GONGTNG586d06RJk7R371794Ac/CHQbAQAA2tV1jxBduHBB6enpWrlypZ577rn2aBMAAECHuu4RotDQUO3fv18Oh6M92gMAANDh/Lpk9uijj2r16tWBbgsAAEBQ+DWpuqmpSb/97W9VUlKioUOHtnqHWUFBQUAaBwAA0BGuKxB98cUXuv3227V//37dddddkqS//vWvPjVcSgMAAF3NdQWixMREVVVVaevWrZK+e1XHr3/9a8XFxbVL4wAAADrCdc0huvRt9u+//77OnTsX0AYBAAB0NL8mVV90aUACAADoiq4rEDkcjlZzhJgzBAAAurrrmkNkWZYee+wx+wWu33zzjWbNmtXqLrMNGzYEroUAupzbn37P7+9+uXRCAFsCAG1zXYFo6tSpPp9/8YtfBLQxAAAAwXBdgWjNmjXt1Q4AAICguaFJ1TcqPz9fP/rRjxQVFaXY2FhNnDhRhw4d8qmxLEtLliyR2+1WRESERo4cqQMHDvjUNDY2au7cuerVq5ciIyOVmZmpEydO+NTU1NQoOztbTqdTTqdT2dnZOnv2bHsfIgAA6AKCGohKS0v15JNPqry8XCUlJfr222+Vnp7ucyv/smXLVFBQoMLCQu3atUsul0tjxoxRXV2dXZOTk6ONGzeqqKhI27ZtU319vTIyMtTc3GzXZGVlqbKyUsXFxSouLlZlZaWys7M79HgBAEDn5LA60b3zp0+fVmxsrEpLS3XvvffKsiy53W7l5OToqaeekvTdaFBcXJxeeOEFzZw5U16vV71799Ybb7yhKVOmSJJOnjyp+Ph4bdq0SWPHjtXBgwc1aNAglZeXKzU1VZJUXl6utLQ0ffbZZxowYMA121ZbWyun0ymv16vo6Oj26wS0qxuZ7IuOwaRqAIHU1r/fQR0hupTX65UkxcTESJKOHDkij8ej9PR0uyY8PFwjRoxQWVmZJKmiokIXLlzwqXG73UpKSrJrtm/fLqfTaYchSRo2bJicTqddc6nGxkbV1tb6LAAA4ObUaQKRZVlasGCB7r77biUlJUmSPB6PJLV6NUhcXJy9zePxKCwsTD169LhqTWxsbKvfjI2NtWsulZ+fb883cjqdio+Pv7EDBAAAnVanCURz5szRp59+qrfffrvVtksf/mhZ1jUfCHlpzeXqr7afxYsXy+v12svx48fbchgAAKALuq7b7tvL3Llz9e677+rjjz9W37597fUul0vSdyM8ffr0sddXV1fbo0Yul0tNTU2qqanxGSWqrq7W8OHD7ZpTp061+t3Tp09f8cW04eHh9gMoAXQcHuoIIBiCOkJkWZbmzJmjDRs2aMuWLUpISPDZnpCQIJfLpZKSEntdU1OTSktL7bCTkpKi0NBQn5qqqirt37/frklLS5PX69XOnTvtmh07dsjr9do1AADAXEEdIXryySf11ltv6X/+538UFRVlz+dxOp2KiIiQw+FQTk6O8vLylJiYqMTEROXl5al79+7Kysqya6dNm6bc3Fz17NlTMTExWrhwoZKTkzV69GhJ0sCBAzVu3DhNnz5dK1eulCTNmDFDGRkZbbrDDAAA3NyCGoheeeUVSdLIkSN91q9Zs0aPPfaYJGnRokVqaGjQ7NmzVVNTo9TUVG3evFlRUVF2/YoVKxQSEqLJkyeroaFBo0aN0tq1a9WtWze7Zv369Zo3b559N1pmZqYKCwvb9wABAECX0KmeQ9SZ8RyimwPPIbq5MYcIwKW65HOIAAAAgoFABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwXqd4uSvQVjxYEQDQHhghAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPFCgt0AmOf2p98LdhMAAPBBIAJw07iRsP3l0gkBbAmAroZABL8wygMAuJkwhwgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI8nVQPADeKVIUDXxwgRAAAwHoEIAAAYj0AEAACMRyACAADGY1I1AOjGJkYD6PoYIQIAAMYjEAEAAONxycxgXCIAAOA7jBABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHhBfZfZxx9/rOXLl6uiokJVVVXauHGjJk6caG+3LEvPPfecXnvtNdXU1Cg1NVW/+c1vNHjwYLumsbFRCxcu1Ntvv62GhgaNGjVKL7/8svr27WvX1NTUaN68eXr33XclSZmZmfqv//ov3XrrrR11qABwWTfyTsEvl04IYEsAswV1hOjcuXMaMmSICgsLL7t92bJlKigoUGFhoXbt2iWXy6UxY8aorq7OrsnJydHGjRtVVFSkbdu2qb6+XhkZGWpubrZrsrKyVFlZqeLiYhUXF6uyslLZ2dntfnwAAKBrcFiWZQW7EZLkcDh8Rogsy5Lb7VZOTo6eeuopSd+NBsXFxemFF17QzJkz5fV61bt3b73xxhuaMmWKJOnkyZOKj4/Xpk2bNHbsWB08eFCDBg1SeXm5UlNTJUnl5eVKS0vTZ599pgEDBrSpfbW1tXI6nfJ6vYqOjg58BwQBb7sHujZGiIBra+vf76BeMruaI0eOyOPxKD093V4XHh6uESNGqKysTDNnzlRFRYUuXLjgU+N2u5WUlKSysjKNHTtW27dvl9PptMOQJA0bNkxOp1NlZWVXDESNjY1qbGy0P9fW1rbDUQJAcHCpDvDVaSdVezweSVJcXJzP+ri4OHubx+NRWFiYevTocdWa2NjYVvuPjY21ay4nPz9fTqfTXuLj42/oeAAAQOfVaUeILnI4HD6fLctqte5Sl9Zcrv5a+1m8eLEWLFhgf66trSUUAehUuOwNBE6nHSFyuVyS1GoUp7q62h41crlcampqUk1NzVVrTp061Wr/p0+fbjX69PfCw8MVHR3tswAAgJtTpw1ECQkJcrlcKikpsdc1NTWptLRUw4cPlySlpKQoNDTUp6aqqkr79++3a9LS0uT1erVz5067ZseOHfJ6vXYNAAAwW1AvmdXX1+v//u//7M9HjhxRZWWlYmJidNtttyknJ0d5eXlKTExUYmKi8vLy1L17d2VlZUmSnE6npk2bptzcXPXs2VMxMTFauHChkpOTNXr0aEnSwIEDNW7cOE2fPl0rV66UJM2YMUMZGRltvsMMAADc3IIaiHbv3q377rvP/nxxzs7UqVO1du1aLVq0SA0NDZo9e7b9YMbNmzcrKirK/s6KFSsUEhKiyZMn2w9mXLt2rbp162bXrF+/XvPmzbPvRsvMzLzis48AAIB5Os1ziDo7nkMEAN/htnt0JW39+91p5xABAAB0FAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxOv3LXQEAncuNPMOMZxihsyIQAQA6DGEKnRWXzAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeLy6AwDQJfDaD7QnRogAAIDxCEQAAMB4XDIDANz0uNyGayEQAQBwFYQpM3DJDAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeNx2DwBAO+GW/a6DQAQAwE2GIHb9uGQGAACMxwgRAACd0I2M8uD6MUIEAACMRyACAADGIxABAADjMYcIAADYgjV3Kdh3tzFCBAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADj8S6zLi5Y75wBAOBmwggRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABjPqED08ssvKyEhQbfccotSUlL0pz/9KdhNAgAAnYAxgeidd95RTk6OnnnmGe3du1f33HOPxo8fr2PHjgW7aQAAIMgclmVZwW5ER0hNTdVdd92lV155xV43cOBATZw4Ufn5+df8fm1trZxOp7xer6KjowPaNl7QCgAw3ZdLJ7TLftv699uIt903NTWpoqJCTz/9tM/69PR0lZWVXfY7jY2NamxstD97vV5J33VsoLU0ng/4PgEA6Era4+/r3+/3WuM/RgSir7/+Ws3NzYqLi/NZHxcXJ4/Hc9nv5Ofn67nnnmu1Pj4+vl3aCACAyZwvte/+6+rq5HQ6r7jdiEB0kcPh8PlsWVardRctXrxYCxYssD+3tLTob3/7m3r27HnF71xJbW2t4uPjdfz48YBfbsP/Rz93DPq5Y9DP7Y8+7hjB7mfLslRXVye3233VOiMCUa9evdStW7dWo0HV1dWtRo0uCg8PV3h4uM+6W2+99YbaER0dzX90HYB+7hj0c8egn9sffdwxgtnPVxsZusiIu8zCwsKUkpKikpISn/UlJSUaPnx4kFoFAAA6CyNGiCRpwYIFys7O1tChQ5WWlqbXXntNx44d06xZs4LdNAAAEGTGBKIpU6bozJkz+o//+A9VVVUpKSlJmzZtUr9+/dr9t8PDw/Xss8+2ugSHwKKfOwb93DHo5/ZHH3eMrtLPxjyHCAAA4EqMmEMEAABwNQQiAABgPAIRAAAwHoEIAAAYj0DUAV5++WUlJCTolltuUUpKiv70pz8Fu0ld1pIlS+RwOHwWl8tlb7csS0uWLJHb7VZERIRGjhypAwcOBLHFXcPHH3+sBx54QG63Ww6HQ//93//ts70t/drY2Ki5c+eqV69eioyMVGZmpk6cONGBR9H5XaufH3vssVbn97Bhw3xq6Oery8/P149+9CNFRUUpNjZWEydO1KFDh3xqOJ9vXFv6uaudzwSidvbOO+8oJydHzzzzjPbu3at77rlH48eP17Fjx4LdtC5r8ODBqqqqspd9+/bZ25YtW6aCggIVFhZq165dcrlcGjNmjOrq6oLY4s7v3LlzGjJkiAoLCy+7vS39mpOTo40bN6qoqEjbtm1TfX29MjIy1Nzc3FGH0eldq58lady4cT7n96ZNm3y2089XV1paqieffFLl5eUqKSnRt99+q/T0dJ07d86u4Xy+cW3pZ6mLnc8W2tWPf/xja9asWT7r/umf/sl6+umng9Siru3ZZ5+1hgwZctltLS0tlsvlspYuXWqv++abbyyn02m9+uqrHdTCrk+StXHjRvtzW/r17NmzVmhoqFVUVGTXfPXVV9b3vvc9q7i4uMPa3pVc2s+WZVlTp061HnzwwSt+h36+ftXV1ZYkq7S01LIszuf2cmk/W1bXO58ZIWpHTU1NqqioUHp6us/69PR0lZWVBalVXd/hw4fldruVkJCghx9+WF988YUk6ciRI/J4PD79HR4erhEjRtDfN6At/VpRUaELFy741LjdbiUlJdH31+mjjz5SbGys+vfvr+nTp6u6utreRj9fP6/XK0mKiYmRxPncXi7t54u60vlMIGpHX3/9tZqbm1u9QDYuLq7Vi2bRNqmpqVq3bp0++OADrVq1Sh6PR8OHD9eZM2fsPqW/A6st/erxeBQWFqYePXpcsQbXNn78eK1fv15btmzRiy++qF27dun+++9XY2OjJPr5elmWpQULFujuu+9WUlKSJM7n9nC5fpa63vlszKs7gsnhcPh8tiyr1Tq0zfjx4+1/JycnKy0tTT/4wQ/0+uuv25P16O/24U+/0vfXZ8qUKfa/k5KSNHToUPXr10/vvfeeJk2adMXv0c+XN2fOHH366afatm1bq22cz4FzpX7uauczI0TtqFevXurWrVurpFtdXd3q/07gn8jISCUnJ+vw4cP23Wb0d2C1pV9dLpeamppUU1NzxRpcvz59+qhfv346fPiwJPr5esydO1fvvvuutm7dqr59+9rrOZ8D60r9fDmd/XwmELWjsLAwpaSkqKSkxGd9SUmJhg8fHqRW3VwaGxt18OBB9enTRwkJCXK5XD793dTUpNLSUvr7BrSlX1NSUhQaGupTU1VVpf3799P3N+DMmTM6fvy4+vTpI4l+bgvLsjRnzhxt2LBBW7ZsUUJCgs92zufAuFY/X06nP587fBq3YYqKiqzQ0FBr9erV1l/+8hcrJyfHioyMtL788stgN61Lys3NtT766CPriy++sMrLy62MjAwrKirK7s+lS5daTqfT2rBhg7Vv3z7r5z//udWnTx+rtrY2yC3v3Orq6qy9e/dae/futSRZBQUF1t69e62jR49altW2fp01a5bVt29f68MPP7T27Nlj3X///daQIUOsb7/9NliH1elcrZ/r6uqs3Nxcq6yszDpy5Ii1detWKy0tzfqHf/gH+vk6/PKXv7ScTqf10UcfWVVVVfZy/vx5u4bz+cZdq5+74vlMIOoAv/nNb6x+/fpZYWFh1l133eVzWyKuz5QpU6w+ffpYoaGhltvttiZNmmQdOHDA3t7S0mI9++yzlsvlssLDw617773X2rdvXxBb3DVs3brVktRqmTp1qmVZbevXhoYGa86cOVZMTIwVERFhZWRkWMeOHQvC0XReV+vn8+fPW+np6Vbv3r2t0NBQ67bbbrOmTp3aqg/p56u7XP9KstasWWPXcD7fuGv1c1c8nx2WZVkdNx4FAADQ+TCHCAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADj/T/+gK9g+/lflgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_TOKEN = 256\n",
    "IMDB_256 = IMDB[IMDB[\"token_length\"]<MAX_TOKEN]\n",
    "IMDB_256[\"token_length\"].plot.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16099    [7545, 1697, 12025, 3621, 1679, 565, 7796, 284...\n",
       "41942    [5178, 15114, 2349, 16260, 834, 180, 4499, 638...\n",
       "16344    [7232, 284, 1705, 4055, 929, 3644, 17954, 3098...\n",
       "26488    [2, 76, 9610, 2801, 4160, 361, 176, 2023, 251,...\n",
       "18847    [1121, 780, 855, 16041, 8047, 661, 65, 134, 85...\n",
       "                               ...                        \n",
       "33736    [1, 711, 7699, 8846, 741, 178, 114, 2138, 1904...\n",
       "7998     [1291, 2146, 508, 284, 2, 223, 1, 80, 223, 282...\n",
       "15666    [269, 3897, 1741, 3668, 700, 19805, 752, 5249,...\n",
       "34507    [653, 13, 94, 11704, 11705, 130, 8338, 856, 13...\n",
       "39446    [98, 957, 10056, 8757, 534, 2, 993, 1393, 5001...\n",
       "Name: review_numbered, Length: 18030, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Valid Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_raw, y_raw = IMDB_256[\"review_numbered\"], IMDB_256[\"sentiment\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_raw, y_raw, test_size=0.5, random_state=0, stratify=y_raw\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=0, stratify=y_train\n",
    ")\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 패딩 작업\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def seq_padding(sequence: pd.Series):\n",
    "    # 정수 인코딩된 시퀀스를 PyTorch 텐서로 변환\n",
    "    encoded_tensors = [torch.tensor(seq) for seq in sequence.to_list()]\n",
    "    # 패딩 적용 (최대 길이에 맞춰 0으로 패딩)\n",
    "    return pad_sequence(encoded_tensors, batch_first=True, padding_value=0, padding_side=\"left\")\n",
    "\n",
    "\n",
    "X_train, X_valid, X_test = seq_padding(X_train), seq_padding(X_valid), seq_padding(X_test)\n",
    "y_train, y_valid, y_test = y_train.apply(int), y_valid.apply(int), y_test.apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded Sequences:\n",
      " tensor([[    0,     0,     0,  ...,  2608,   933,   134],\n",
      "        [    0,     0,     0,  ..., 17386,   244,   134],\n",
      "        [    0,     0,     0,  ...,     1,   634,  1140],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,  6972,   762,   134],\n",
      "        [    0,     0,     0,  ...,     1,   474,  2502],\n",
      "        [    0,     0,     0,  ...,   293,  1882,   134]], dtype=torch.int32)\n",
      "Labels:\n",
      " tensor([0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
      "        1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3640961/3639225804.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 6. 패딩이 적용된 시퀀스와 레이블 합치기\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "def dataloader_gen(x, y, batch_size=BATCH_SIZE):\n",
    "    x = torch.tensor(x, dtype=torch.int32)\n",
    "    y = torch.tensor(y, dtype=torch.long)\n",
    "    return DataLoader(TensorDataset(x, y), batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "dataloader = dataloader_gen(X_train, y_train.to_numpy())\n",
    "valid_dataloader = dataloader_gen(X_valid, y_valid.to_numpy())\n",
    "test_dataloader = dataloader_gen(X_test, y_test.to_numpy())\n",
    "\n",
    "\n",
    "# 배치를 확인하며 첫 번째 배치 출력\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    print(\"Padded Sequences:\\n\", inputs)\n",
    "    print(\"Labels:\\n\", targets)\n",
    "    break  # 첫 번째 배치만 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Param\n",
    "LEARNING_RATE = 0.00001\n",
    "N_EPOCHS = 20\n",
    "\n",
    "\n",
    "EMBED_SIZE = 64\n",
    "HIDDEN_SIZE = 512\n",
    "OUTPUT_DIM = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalysisRNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_dim=VOCAB_SIZE,\n",
    "        embedding_dim=EMBED_SIZE,\n",
    "        hidden_dim=HIDDEN_SIZE,\n",
    "        output_dim=OUTPUT_DIM,\n",
    "        device=device,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_dim, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        embed = self.embed(x)\n",
    "\n",
    "        # h_0 = torch.zeros(,x.shape[0])\n",
    "        y_t_list, h_t_list = self.rnn(embed)\n",
    "        h_t = h_t_list.squeeze(0)\n",
    "        # target = y_t_list[:, -1, :]\n",
    "\n",
    "        feature = self.fc1(h_t)\n",
    "        feature = F.relu(feature)\n",
    "        output = self.fc2(feature)\n",
    "        return self.softmax(output)\n",
    "\n",
    "\n",
    "# Training setup\n",
    "model = SentimentAnalysisRNN(vocab_dim=VOCAB_SIZE, device=device).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(logits, labels):\n",
    "    # _, predicted = torch.max(logits, 1)\n",
    "    predicted = torch.argmax(logits, dim=1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    total = labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "def evaluate(model, valid_dataloader, criterion, device):\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 데이터로더로부터 배치 크기만큼의 데이터를 연속으로 로드\n",
    "        for batch_X, batch_y in valid_dataloader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            # 모델의 예측값\n",
    "            logits = model(batch_X)\n",
    "\n",
    "            # 손실을 계산\n",
    "            loss = criterion(logits, batch_y)\n",
    "\n",
    "            # 정확도와 손실을 계산함\n",
    "            val_loss += loss.item()\n",
    "            val_correct += calculate_accuracy(logits, batch_y) * batch_y.size(0)\n",
    "            val_total += batch_y.size(0)\n",
    "\n",
    "    val_accuracy = val_correct / val_total\n",
    "    val_loss /= len(valid_dataloader)\n",
    "\n",
    "    return val_loss, val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:\n",
      "Train Loss: 0.5904, Train Accuracy: 0.7074\n",
      "Validation Loss: 0.5810, Validation Accuracy: 0.7225\n",
      "Validation loss improved from inf to 0.5810. 체크포인트를 저장합니다.\n",
      "Epoch 2/100:\n",
      "Train Loss: 0.5710, Train Accuracy: 0.7249\n",
      "Validation Loss: 0.5623, Validation Accuracy: 0.7396\n",
      "Validation loss improved from 0.5810 to 0.5623. 체크포인트를 저장합니다.\n",
      "Epoch 3/100:\n",
      "Train Loss: 0.5277, Train Accuracy: 0.7737\n",
      "Validation Loss: 0.5286, Validation Accuracy: 0.7780\n",
      "Validation loss improved from 0.5623 to 0.5286. 체크포인트를 저장합니다.\n",
      "Epoch 4/100:\n",
      "Train Loss: 0.5085, Train Accuracy: 0.7960\n",
      "Validation Loss: 0.5414, Validation Accuracy: 0.7573\n",
      "Epoch 5/100:\n",
      "Train Loss: 0.4977, Train Accuracy: 0.8104\n",
      "Validation Loss: 0.5294, Validation Accuracy: 0.7742\n",
      "Epoch 6/100:\n",
      "Train Loss: 0.4904, Train Accuracy: 0.8179\n",
      "Validation Loss: 0.5281, Validation Accuracy: 0.7788\n",
      "Validation loss improved from 0.5286 to 0.5281. 체크포인트를 저장합니다.\n",
      "Epoch 7/100:\n",
      "Train Loss: 0.4720, Train Accuracy: 0.8368\n",
      "Validation Loss: 0.5305, Validation Accuracy: 0.7711\n",
      "Epoch 8/100:\n",
      "Train Loss: 0.4871, Train Accuracy: 0.8193\n",
      "Validation Loss: 0.5775, Validation Accuracy: 0.7172\n",
      "Epoch 9/100:\n",
      "Train Loss: 0.4678, Train Accuracy: 0.8399\n",
      "Validation Loss: 0.5270, Validation Accuracy: 0.7753\n",
      "Validation loss improved from 0.5281 to 0.5270. 체크포인트를 저장합니다.\n",
      "Epoch 10/100:\n",
      "Train Loss: 0.4468, Train Accuracy: 0.8638\n",
      "Validation Loss: 0.5252, Validation Accuracy: 0.7784\n",
      "Validation loss improved from 0.5270 to 0.5252. 체크포인트를 저장합니다.\n",
      "Epoch 11/100:\n",
      "Train Loss: 0.4353, Train Accuracy: 0.8775\n",
      "Validation Loss: 0.5216, Validation Accuracy: 0.7853\n",
      "Validation loss improved from 0.5252 to 0.5216. 체크포인트를 저장합니다.\n",
      "Epoch 12/100:\n",
      "Train Loss: 0.4245, Train Accuracy: 0.8885\n",
      "Validation Loss: 0.5512, Validation Accuracy: 0.7513\n",
      "Epoch 13/100:\n",
      "Train Loss: 0.4210, Train Accuracy: 0.8907\n",
      "Validation Loss: 0.5289, Validation Accuracy: 0.7791\n",
      "Epoch 14/100:\n",
      "Train Loss: 0.4138, Train Accuracy: 0.8987\n",
      "Validation Loss: 0.5325, Validation Accuracy: 0.7737\n",
      "Epoch 15/100:\n",
      "Train Loss: 0.4133, Train Accuracy: 0.8987\n",
      "Validation Loss: 0.5471, Validation Accuracy: 0.7547\n",
      "Epoch 16/100:\n",
      "Train Loss: 0.4129, Train Accuracy: 0.8999\n",
      "Validation Loss: 0.5419, Validation Accuracy: 0.7653\n",
      "Epoch 17/100:\n",
      "Train Loss: 0.4002, Train Accuracy: 0.9133\n",
      "Validation Loss: 0.5522, Validation Accuracy: 0.7540\n",
      "Epoch 18/100:\n",
      "Train Loss: 0.4201, Train Accuracy: 0.8920\n",
      "Validation Loss: 0.6790, Validation Accuracy: 0.6207\n",
      "Epoch 19/100:\n",
      "Train Loss: 0.5528, Train Accuracy: 0.7496\n",
      "Validation Loss: 0.5401, Validation Accuracy: 0.7689\n",
      "Epoch 20/100:\n",
      "Train Loss: 0.4310, Train Accuracy: 0.8794\n",
      "Validation Loss: 0.5650, Validation Accuracy: 0.7360\n",
      "Epoch 21/100:\n",
      "Train Loss: 0.4271, Train Accuracy: 0.8827\n",
      "Validation Loss: 0.5486, Validation Accuracy: 0.7538\n",
      "Epoch 22/100:\n",
      "Train Loss: 0.4071, Train Accuracy: 0.9045\n",
      "Validation Loss: 0.5301, Validation Accuracy: 0.7768\n",
      "Epoch 23/100:\n",
      "Train Loss: 0.3920, Train Accuracy: 0.9214\n",
      "Validation Loss: 0.5341, Validation Accuracy: 0.7715\n",
      "Epoch 24/100:\n",
      "Train Loss: 0.3838, Train Accuracy: 0.9302\n",
      "Validation Loss: 0.5422, Validation Accuracy: 0.7651\n",
      "Epoch 25/100:\n",
      "Train Loss: 0.3779, Train Accuracy: 0.9364\n",
      "Validation Loss: 0.5417, Validation Accuracy: 0.7638\n",
      "Epoch 26/100:\n",
      "Train Loss: 0.3783, Train Accuracy: 0.9351\n",
      "Validation Loss: 0.5316, Validation Accuracy: 0.7766\n",
      "Epoch 27/100:\n",
      "Train Loss: 0.3802, Train Accuracy: 0.9333\n",
      "Validation Loss: 0.5251, Validation Accuracy: 0.7819\n",
      "Epoch 28/100:\n",
      "Train Loss: 0.3759, Train Accuracy: 0.9375\n",
      "Validation Loss: 0.5505, Validation Accuracy: 0.7567\n",
      "Epoch 29/100:\n",
      "Train Loss: 0.3751, Train Accuracy: 0.9385\n",
      "Validation Loss: 0.5420, Validation Accuracy: 0.7653\n",
      "Epoch 30/100:\n",
      "Train Loss: 0.3729, Train Accuracy: 0.9402\n",
      "Validation Loss: 0.5509, Validation Accuracy: 0.7573\n",
      "Epoch 31/100:\n",
      "Train Loss: 0.3880, Train Accuracy: 0.9230\n",
      "Validation Loss: 0.5435, Validation Accuracy: 0.7633\n",
      "Epoch 32/100:\n",
      "Train Loss: 0.3907, Train Accuracy: 0.9209\n",
      "Validation Loss: 0.5465, Validation Accuracy: 0.7618\n",
      "Epoch 33/100:\n",
      "Train Loss: 0.3700, Train Accuracy: 0.9437\n",
      "Validation Loss: 0.5350, Validation Accuracy: 0.7715\n",
      "Epoch 34/100:\n",
      "Train Loss: 0.3689, Train Accuracy: 0.9443\n",
      "Validation Loss: 0.5301, Validation Accuracy: 0.7791\n",
      "Epoch 35/100:\n",
      "Train Loss: 0.3780, Train Accuracy: 0.9338\n",
      "Validation Loss: 0.5470, Validation Accuracy: 0.7587\n",
      "Epoch 36/100:\n",
      "Train Loss: 0.3689, Train Accuracy: 0.9445\n",
      "Validation Loss: 0.5527, Validation Accuracy: 0.7560\n",
      "Epoch 37/100:\n",
      "Train Loss: 0.3669, Train Accuracy: 0.9467\n",
      "Validation Loss: 0.5276, Validation Accuracy: 0.7822\n",
      "Epoch 38/100:\n",
      "Train Loss: 0.3631, Train Accuracy: 0.9508\n",
      "Validation Loss: 0.5577, Validation Accuracy: 0.7500\n",
      "Epoch 39/100:\n",
      "Train Loss: 0.5386, Train Accuracy: 0.7768\n",
      "Validation Loss: 0.8160, Validation Accuracy: 0.4973\n",
      "Epoch 40/100:\n",
      "Train Loss: 0.8149, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8150, Validation Accuracy: 0.4973\n",
      "Epoch 41/100:\n",
      "Train Loss: 0.8151, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8152, Validation Accuracy: 0.4973\n",
      "Epoch 42/100:\n",
      "Train Loss: 0.8146, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8157, Validation Accuracy: 0.4973\n",
      "Epoch 43/100:\n",
      "Train Loss: 0.8146, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8159, Validation Accuracy: 0.4973\n",
      "Epoch 44/100:\n",
      "Train Loss: 0.8153, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8163, Validation Accuracy: 0.4973\n",
      "Epoch 45/100:\n",
      "Train Loss: 0.8148, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8148, Validation Accuracy: 0.4973\n",
      "Epoch 46/100:\n",
      "Train Loss: 0.8149, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8145, Validation Accuracy: 0.4973\n",
      "Epoch 47/100:\n",
      "Train Loss: 0.8141, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8157, Validation Accuracy: 0.4973\n",
      "Epoch 48/100:\n",
      "Train Loss: 0.8146, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8160, Validation Accuracy: 0.4973\n",
      "Epoch 49/100:\n",
      "Train Loss: 0.8151, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8156, Validation Accuracy: 0.4973\n",
      "Epoch 50/100:\n",
      "Train Loss: 0.8153, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8161, Validation Accuracy: 0.4973\n",
      "Epoch 51/100:\n",
      "Train Loss: 0.8143, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8174, Validation Accuracy: 0.4973\n",
      "Epoch 52/100:\n",
      "Train Loss: 0.8154, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8157, Validation Accuracy: 0.4973\n",
      "Epoch 53/100:\n",
      "Train Loss: 0.8154, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8154, Validation Accuracy: 0.4973\n",
      "Epoch 54/100:\n",
      "Train Loss: 0.8145, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8156, Validation Accuracy: 0.4973\n",
      "Epoch 55/100:\n",
      "Train Loss: 0.8149, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8146, Validation Accuracy: 0.4973\n",
      "Epoch 56/100:\n",
      "Train Loss: 0.8146, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8150, Validation Accuracy: 0.4973\n",
      "Epoch 57/100:\n",
      "Train Loss: 0.8160, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8159, Validation Accuracy: 0.4973\n",
      "Epoch 58/100:\n",
      "Train Loss: 0.8150, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8150, Validation Accuracy: 0.4973\n",
      "Epoch 59/100:\n",
      "Train Loss: 0.8143, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8174, Validation Accuracy: 0.4973\n",
      "Epoch 60/100:\n",
      "Train Loss: 0.8150, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8161, Validation Accuracy: 0.4973\n",
      "Epoch 61/100:\n",
      "Train Loss: 0.8151, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8156, Validation Accuracy: 0.4973\n",
      "Epoch 62/100:\n",
      "Train Loss: 0.8154, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8154, Validation Accuracy: 0.4973\n",
      "Epoch 63/100:\n",
      "Train Loss: 0.8152, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8154, Validation Accuracy: 0.4973\n",
      "Epoch 64/100:\n",
      "Train Loss: 0.8152, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8167, Validation Accuracy: 0.4973\n",
      "Epoch 65/100:\n",
      "Train Loss: 0.8157, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8150, Validation Accuracy: 0.4973\n",
      "Epoch 66/100:\n",
      "Train Loss: 0.8149, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8174, Validation Accuracy: 0.4973\n",
      "Epoch 67/100:\n",
      "Train Loss: 0.8148, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8168, Validation Accuracy: 0.4973\n",
      "Epoch 68/100:\n",
      "Train Loss: 0.8160, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8149, Validation Accuracy: 0.4973\n",
      "Epoch 69/100:\n",
      "Train Loss: 0.8147, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8163, Validation Accuracy: 0.4973\n",
      "Epoch 70/100:\n",
      "Train Loss: 0.8142, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8168, Validation Accuracy: 0.4973\n",
      "Epoch 71/100:\n",
      "Train Loss: 0.8140, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8143, Validation Accuracy: 0.4973\n",
      "Epoch 72/100:\n",
      "Train Loss: 0.8151, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8159, Validation Accuracy: 0.4973\n",
      "Epoch 73/100:\n",
      "Train Loss: 0.8146, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8160, Validation Accuracy: 0.4973\n",
      "Epoch 74/100:\n",
      "Train Loss: 0.8155, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8159, Validation Accuracy: 0.4973\n",
      "Epoch 75/100:\n",
      "Train Loss: 0.8145, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8164, Validation Accuracy: 0.4973\n",
      "Epoch 76/100:\n",
      "Train Loss: 0.8154, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8175, Validation Accuracy: 0.4973\n",
      "Epoch 77/100:\n",
      "Train Loss: 0.8149, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8164, Validation Accuracy: 0.4973\n",
      "Epoch 78/100:\n",
      "Train Loss: 0.8140, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8156, Validation Accuracy: 0.4973\n",
      "Epoch 79/100:\n",
      "Train Loss: 0.8154, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8154, Validation Accuracy: 0.4973\n",
      "Epoch 80/100:\n",
      "Train Loss: 0.8142, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8146, Validation Accuracy: 0.4973\n",
      "Epoch 81/100:\n",
      "Train Loss: 0.8153, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8148, Validation Accuracy: 0.4973\n",
      "Epoch 82/100:\n",
      "Train Loss: 0.8149, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8166, Validation Accuracy: 0.4973\n",
      "Epoch 83/100:\n",
      "Train Loss: 0.8145, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8153, Validation Accuracy: 0.4973\n",
      "Epoch 84/100:\n",
      "Train Loss: 0.8151, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8161, Validation Accuracy: 0.4973\n",
      "Epoch 85/100:\n",
      "Train Loss: 0.8155, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8159, Validation Accuracy: 0.4973\n",
      "Epoch 86/100:\n",
      "Train Loss: 0.8150, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8156, Validation Accuracy: 0.4973\n",
      "Epoch 87/100:\n",
      "Train Loss: 0.8143, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8160, Validation Accuracy: 0.4973\n",
      "Epoch 88/100:\n",
      "Train Loss: 0.8144, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8159, Validation Accuracy: 0.4973\n",
      "Epoch 89/100:\n",
      "Train Loss: 0.8146, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8146, Validation Accuracy: 0.4973\n",
      "Epoch 90/100:\n",
      "Train Loss: 0.8151, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8156, Validation Accuracy: 0.4973\n",
      "Epoch 91/100:\n",
      "Train Loss: 0.8153, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8153, Validation Accuracy: 0.4973\n",
      "Epoch 92/100:\n",
      "Train Loss: 0.8151, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8146, Validation Accuracy: 0.4973\n",
      "Epoch 93/100:\n",
      "Train Loss: 0.8147, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8148, Validation Accuracy: 0.4973\n",
      "Epoch 94/100:\n",
      "Train Loss: 0.8153, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8152, Validation Accuracy: 0.4973\n",
      "Epoch 95/100:\n",
      "Train Loss: 0.8143, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8164, Validation Accuracy: 0.4973\n",
      "Epoch 96/100:\n",
      "Train Loss: 0.8154, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8167, Validation Accuracy: 0.4973\n",
      "Epoch 97/100:\n",
      "Train Loss: 0.8149, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8156, Validation Accuracy: 0.4973\n",
      "Epoch 98/100:\n",
      "Train Loss: 0.8144, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8143, Validation Accuracy: 0.4973\n",
      "Epoch 99/100:\n",
      "Train Loss: 0.8143, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8182, Validation Accuracy: 0.4973\n",
      "Epoch 100/100:\n",
      "Train Loss: 0.8148, Train Accuracy: 0.4984\n",
      "Validation Loss: 0.8152, Validation Accuracy: 0.4973\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')  # 검증 손실의 최저 값을 추적하기 위한 변수로, 초기값은 매우 큰 값으로 설정합니다.\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        x_batch, y_batch = samples\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        predicted = model(x_batch)\n",
    "        loss = loss_fn(predicted, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_correct += calculate_accuracy(predicted, y_batch) * y_batch.size(0)\n",
    "        train_total += y_batch.size(0)\n",
    "        \n",
    "    train_accuracy = train_correct / train_total\n",
    "    train_loss /= len(dataloader)\n",
    "    \n",
    "      # Validation\n",
    "    val_loss, val_accuracy = evaluate(model, valid_dataloader, loss_fn, device)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{N_EPOCHS}:')\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # 검증 손실이 최소일 때 체크포인트 저장\n",
    "    if val_loss < best_val_loss:\n",
    "        print(f'Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. 체크포인트를 저장합니다.')\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model_checkpoint.pth')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'modules'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save_json, now\n\u001b[1;32m      3\u001b[0m save_json(\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./training_param_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnow()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     },\n\u001b[1;32m     14\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'modules'"
     ]
    }
   ],
   "source": [
    "from modules.util import save_json, now\n",
    "\n",
    "save_json(\n",
    "    f\"./training_param_{now()}.json\",\n",
    "    {\n",
    "        \"voca_frequency_thresold\": FREQ_THRESHOLD,\n",
    "        \"token_truncation\": MAX_TOKEN,\n",
    "        \"lr\": LEARNING_RATE,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"embed_dim\": EMBED_SIZE,\n",
    "        \"rnn_hidden_dim\": HIDDEN_SIZE,\n",
    "        \"output_dim\": OUTPUT_DIM,\n",
    "    },\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentLSTM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
